[0] B├üO C├üO NGHI├èN Cß╗¿U ─Éß╗Ç T├ÇI
[1] X├éY Dß╗░NG Hß╗å THß╗ÉNG NHß║¼N DIß╗åN Cß║óM X├ÜC KHU├öN Mß║╢T
THEO THß╗£I GIAN THß╗░C TRONG CUß╗ÿC Gß╗îI VIDEO
[3] 1.1. ─ÉIß╗ÇU TRA Tß╗öNG QUAN
[4] 1.1.1. T├¡nh cß║Ñp thiß║┐t cß╗ºa ─æß╗ü t├ái
[5] Trong nhß╗»ng n─âm gß║ºn ─æ├óy, ─æß║╖c biß╗çt sau ─æß║íi dß╗ïch COVID-19, xu h╞░ß╗¢ng l├ám viß╗çc v├á hß╗ìc tß║¡p tß╗½ xa ─æ├ú trß╗ƒ th├ánh mß╗Öt phß║ºn kh├┤ng thß╗â thiß║┐u trong cuß╗Öc sß╗æng hiß╗çn ─æß║íi. Theo thß╗æng k├¬:
[6] N─âm 2025, c├│ h╞ín 70% doanh nghiß╗çp tr├¬n to├án cß║ºu ├íp dß╗Ñng m├┤ h├¼nh l├ám viß╗çc hybrid (kß║┐t hß╗úp trß╗▒c tiß║┐p v├á tß╗½ xa)
[7] Sß╗æ l╞░ß╗úng ng╞░ß╗¥i d├╣ng c├íc nß╗ün tß║úng video call nh╞░ Zoom, Google Meet, Microsoft Teams t─âng h╞ín 300% so vß╗¢i n─âm 2019
[8] Thß╗ï tr╞░ß╗¥ng gi├ío dß╗Ñc trß╗▒c tuyß║┐n (E-Learning) dß╗▒ kiß║┐n ─æß║ít 645 tß╗╖ USD v├áo n─âm 2030
[9] H╞ín 65% cuß╗Öc hß╗ìp doanh nghiß╗çp hiß╗çn nay ─æ╞░ß╗úc thß╗▒c hiß╗çn qua video conference
[10] C├íc vß║Ñn ─æß╗ü tß╗ôn tß║íi trong giao tiß║┐p trß╗▒c tuyß║┐n:
[11] Kh├│ nß║»m bß║»t cß║úm x├║c thß║¡t sß╗▒: Trong m├┤i tr╞░ß╗¥ng trß╗▒c tuyß║┐n, viß╗çc ─æß╗ìc ng├┤n ngß╗» c╞í thß╗â v├á biß╗âu cß║úm khu├┤n mß║╖t trß╗ƒ n├¬n kh├│ kh─ân h╞ín do hß║ín chß║┐ vß╗ü g├│c camera, ─æß╗Ö ph├ón giß║úi v├á ─æß╗Ö trß╗à mß║íng.
[12] Thiß║┐u phß║ún hß╗ôi tß╗⌐c th├¼: Gi├ío vi├¬n kh├┤ng thß╗â quan s├ít ─æ╞░ß╗úc mß╗⌐c ─æß╗Ö hiß╗âu b├ái cß╗ºa hß╗ìc sinh nh╞░ trong lß╗¢p hß╗ìc truyß╗ün thß╗æng; nh├á quß║ún l├╜ kh├│ ─æ├ính gi├í ─æ╞░ß╗úc tinh thß║ºn l├ám viß╗çc cß╗ºa nh├ón vi├¬n.
[13] Hiß╗çu suß║Ñt giao tiß║┐p giß║úm: Nghi├¬n cß╗⌐u cho thß║Ñy hiß╗çu quß║ú giao tiß║┐p qua video call chß╗ë ─æß║ít khoß║úng 60-70% so vß╗¢i giao tiß║┐p trß╗▒c tiß║┐p, mß╗Öt phß║ºn do thiß║┐u th├┤ng tin vß╗ü cß║úm x├║c.
[14] "Zoom fatigue" (Mß╗çt mß╗Åi Zoom): Ng╞░ß╗¥i d├╣ng cß║úm thß║Ñy kiß╗çt sß╗⌐c sau c├íc cuß╗Öc hß╗ìp online do phß║úi tß║¡p trung cao ─æß╗Ö ─æß╗â ─æß╗ìc vß╗ï ng╞░ß╗¥i ─æß╗æi diß╗çn.
[15] Giß║úi ph├íp ─æß╗ü xuß║Ñt:
[16] Viß╗çc ß╗⌐ng dß╗Ñng tr├¡ tuß╗ç nh├ón tß║ío (AI) ─æß╗â nhß║¡n diß╗çn cß║úm x├║c khu├┤n mß║╖t theo thß╗¥i gian thß╗▒c trong c├íc cuß╗Öc gß╗ìi video sß║╜ gi├║p:
[17] Tß╗▒ ─æß╗Öng ph├ón t├¡ch v├á hiß╗ân thß╗ï cß║úm x├║c cß╗ºa ng╞░ß╗¥i tham gia
[18] Cung cß║Ñp th├┤ng tin phß║ún hß╗ôi trß╗▒c quan cho ng╞░ß╗¥i n├│i/gi├ío vi├¬n
[19] Tß║ío b├ío c├ío thß╗æng k├¬ cß║úm x├║c sau cuß╗Öc hß╗ìp ─æß╗â ─æ├ính gi├í hiß╗çu quß║ú
[20] Hß╗ù trß╗ú ra quyß║┐t ─æß╗ïnh dß╗▒a tr├¬n dß╗» liß╗çu cß║úm x├║c thß╗▒c tß║┐
[21] 1.1.2. Tß╗òng quan c├íc giß║úi ph├íp kß╗╣ thuß║¡t hiß╗çn c├│
[22] L─⌐nh vß╗▒c nhß║¡n diß╗çn cß║úm x├║c khu├┤n mß║╖t (Facial Emotion Recognition - FER) ─æ├ú ─æ╞░ß╗úc nghi├¬n cß╗⌐u rß╗Öng r├úi vß╗¢i nhiß╗üu ph╞░╞íng ph├íp tiß║┐p cß║¡n kh├íc nhau:
[23] Bß║úng 1: So s├ính c├íc ph╞░╞íng ph├íp kß╗╣ thuß║¡t nhß║¡n diß╗çn cß║úm x├║c
[25] C├íc c├┤ng tr├¼nh nghi├¬n cß╗⌐u ti├¬u biß╗âu:
[26] Goodfellow et al. (2013) - FER2013 Challenge: ─Éß║╖t nß╗ün m├│ng cho b├ái to├ín FER vß╗¢i dataset chuß║⌐n 35,887 ß║únh, 7 cß║úm x├║c
[27] Mollahosseini et al. (2017) - AffectNet: Dataset lß╗¢n nhß║Ñt vß╗¢i 450,000+ ß║únh, ─æß║ít 58% accuracy tr├¬n 8 classes
[28] Li & Deng (2020) - Deep Facial Expression Recognition Survey: Tß╗òng hß╗úp to├án diß╗çn c├íc ph╞░╞íng ph├íp tß╗½ 2013-2020
[29] Pham et al. (2021) - Facial Expression Recognition using Residual Attention: ─Éß║ít 76% tr├¬n FER2013 vß╗¢i attention mechanism
[30] 1.1.3. C├íc sß║ún phß║⌐m th╞░╞íng mß║íi li├¬n quan
[31] Hiß╗çn nay, nhiß╗üu c├┤ng ty ─æ├ú ph├ít triß╗ân c├íc sß║ún phß║⌐m v├á dß╗ïch vß╗Ñ li├¬n quan ─æß║┐n nhß║¡n diß╗çn cß║úm x├║c:
[32] Bß║úng 2: C├íc sß║ún phß║⌐m th╞░╞íng mß║íi tr├¬n thß╗ï tr╞░ß╗¥ng
[34] Khoß║úng trß╗æng thß╗ï tr╞░ß╗¥ng (Gap Analysis):
[35] C├íc sß║ún phß║⌐m th╞░╞íng mß║íi ─æa phß║ºn l├á cloud-based ΓåÆ lo ngß║íi vß╗ü bß║úo mß║¡t dß╗» liß╗çu khu├┤n mß║╖t
[36] Chi ph├¡ cao cho doanh nghiß╗çp nhß╗Å v├á tß╗ò chß╗⌐c gi├ío dß╗Ñc
[37] Thiß║┐u giß║úi ph├íp t├¡ch hß╗úp trß╗▒c tiß║┐p v├áo c├íc nß╗ün tß║úng video call phß╗ò biß║┐n
[38] C├íc giß║úi ph├íp open-source thiß║┐u giao diß╗çn th├ón thiß╗çn v├á hß╗ù trß╗ú real-time tß╗æi ╞░u
[39] 1.2. ─Éß╗Ç XUß║ñT GIß║óI PH├üP S╞á Bß╗ÿ
[40] 1.2.1. Giß║úi ph├íp kß╗╣ thuß║¡t ─æß╗ü xuß║Ñt
[41] Dß╗▒a tr├¬n ph├ón t├¡ch tß╗òng quan, ─æß╗ü t├ái ─æß╗ü xuß║Ñt x├óy dß╗▒ng hß╗ç thß╗æng nhß║¡n diß╗çn cß║úm x├║c vß╗¢i c├íc ─æß║╖c ─æiß╗âm:
[42] Xß╗¡ l├╜ ho├án to├án local (on-device) ─æß╗â ─æß║úm bß║úo bß║úo mß║¡t
[43] T├¡ch hß╗úp dß║íng Browser Extension cho c├íc nß╗ün tß║úng video call phß╗ò biß║┐n
[44] Sß╗¡ dß╗Ñng Deep Learning vß╗¢i Transfer Learning ─æß╗â tß╗æi ╞░u ─æß╗Ö ch├¡nh x├íc v├á tß╗æc ─æß╗Ö
[45] Giao diß╗çn trß╗▒c quan, dß╗à sß╗¡ dß╗Ñng
[46] Chi ph├¡ triß╗ân khai thß║Ñp (open-source)
[47] 1.2.2. S╞í ─æß╗ô khß╗æi hß╗ç thß╗æng
[48] ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ
Γöé                         KIß║╛N TR├ÜC Hß╗å THß╗ÉNG                               Γöé
Γö£ΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöñ
Γöé                                                                          Γöé
Γöé  ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ     ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ     ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ Γöé
Γöé  Γöé   INPUT      Γöé     Γöé  PROCESSING  Γöé     Γöé        OUTPUT            Γöé Γöé
Γöé  Γöé              Γöé     Γöé              Γöé     Γöé                          Γöé Γöé
Γöé  Γöé  Webcam/     ΓöéΓöÇΓöÇΓöÇΓöÇΓû║Γöé  Face        ΓöéΓöÇΓöÇΓöÇΓöÇΓû║Γöé  Emotion Labels          Γöé Γöé
Γöé  Γöé  Video Call  Γöé     Γöé  Detection   Γöé     Γöé  (Happy, Sad, Angry,...) Γöé Γöé
Γöé  Γöé              Γöé     Γöé  (MediaPipe) Γöé     Γöé                          Γöé Γöé
Γöé  ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ     ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ     Γöé  Confidence Scores       Γöé Γöé
Γöé                              Γöé              Γöé  (0-100%)                Γöé Γöé
Γöé                              Γû╝              Γöé                          Γöé Γöé
Γöé                       ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ     Γöé  Statistics Dashboard    Γöé Γöé
Γöé                       Γöé PreprocessingΓöé     Γöé  (Charts, Reports)       Γöé Γöé
Γöé                       Γöé - Crop face  Γöé     Γöé                          Γöé Γöé
Γöé                       Γöé - Resize     ΓöéΓöÇΓöÇΓöÇΓöÇΓû║Γöé  Overlay UI tr├¬n video   Γöé Γöé
Γöé                       Γöé - Normalize  Γöé     Γöé                          Γöé Γöé
Γöé                       ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ     ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ Γöé
Γöé                              Γöé                                           Γöé
Γöé                              Γû╝                                           Γöé
Γöé                       ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ                                  Γöé
Γöé                       Γöé  AI MODEL    Γöé                                  Γöé
Γöé                       Γöé  - CNN       Γöé                                  Γöé
Γöé                       Γöé  - 7 classes Γöé                                  Γöé
Γöé                       ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ                                  Γöé
Γöé                                                                          Γöé
ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ
[49] M├┤ tß║ú c├íc th├ánh phß║ºn:
[50] Input Layer: Thu nhß║¡n video tß╗½ webcam hoß║╖c capture tß╗½ video call (Zoom, Meet, Teams). Sß╗¡ dß╗Ñng WebRTC hoß║╖c Canvas API.
[51] Face Detection: Sß╗¡ dß╗Ñng MediaPipe Face Detection hoß║╖c MTCNN ─æß╗â ph├ít hiß╗çn v├á ─æß╗ïnh vß╗ï khu├┤n mß║╖t trong frame. Output: Bounding box coordinates.
[52] Preprocessing: Cß║»t v├╣ng khu├┤n mß║╖t, resize vß╗ü 48├ù48 pixels, chuyß╗ân sang grayscale, normalize vß╗ü [0,1].
[53] AI Model: Mß║íng CNN t├╣y chß╗ënh hoß║╖c Transfer Learning (EfficientNet/ResNet). Input: 48├ù48├ù1, Output: 7 class probabilities.
[54] Output Layer: Hiß╗ân thß╗ï emotion label, confidence score, overlay UI, v├á statistics dashboard.
[55] 1.2.3. Quy tr├¼nh thiß║┐t kß║┐ v├á ph├ít triß╗ân
[56] ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ
Γöé                       QUY TR├îNH PH├üT TRIß╗éN                              Γöé
Γö£ΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöñ
Γöé                                                                          Γöé
Γöé   PHASE 1              PHASE 2              PHASE 3              PHASE 4 Γöé
Γöé   Research             Development          Integration          Testing Γöé
Γöé                                                                          Γöé
Γöé   ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ         ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ          ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ         ΓöîΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÉ Γöé
Γöé   Γöé Nghi├¬n  Γöé         Γöé X├óy     Γöé          Γöé T├¡ch    Γöé         Γöé Kiß╗âm  ΓöéΓöé
Γöé   Γöé cß╗⌐u l├╜  ΓöéΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓû║Γöé dß╗▒ng    ΓöéΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓû║Γöé hß╗úp hß╗ç  ΓöéΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓû║Γöé thß╗¡ & ΓöéΓöé
Γöé   Γöé thuyß║┐t  Γöé         Γöé model   Γöé          Γöé thß╗æng   Γöé         Γöé ─æ├ính  ΓöéΓöé
Γöé   Γöé         Γöé         Γöé AI      Γöé          Γöé         Γöé         Γöé gi├í   ΓöéΓöé
Γöé   ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ         ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ          ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ         ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿΓöé
Γöé       Γöé                   Γöé                    Γöé                    Γöé   Γöé
Γöé       Γû╝                   Γû╝                    Γû╝                    Γû╝   Γöé
Γöé   ΓÇó Khß║úo s├ít          ΓÇó Data prep          ΓÇó Backend API        ΓÇó Unit  Γöé
Γöé   ΓÇó State-of-art      ΓÇó Training           ΓÇó Frontend           ΓÇó Integ Γöé
Γöé   ΓÇó Chß╗ìn dataset      ΓÇó Optimization       ΓÇó Extension          ΓÇó Perf  Γöé
Γöé   ΓÇó Chß╗ìn model        ΓÇó Evaluation         ΓÇó Deployment         ΓÇó UAT   Γöé
Γöé                                                                         Γöé
Γöé   Tuß║ºn 1-3            Tuß║ºn 4-8             Tuß║ºn 9-12           Tuß║ºn 13+ Γöé
Γöé                                                                         Γöé
ΓööΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÇΓöÿ
[57] 1.2.4. C├┤ng cß╗Ñ v├á nguy├¬n vß║¡t liß╗çu cß║ºn thiß║┐t
[58] Bß║úng 3: Danh s├ích c├┤ng cß╗Ñ v├á thiß║┐t bß╗ï
[60] Tß╗òng chi ph├¡ ╞░ß╗¢c t├¡nh: 750,000 - 1,500,000 VN─É (chß╗º yß║┐u l├á chi ph├¡ GPU cloud nß║┐u cß║ºn)
[61] 1.3. Dß╗░ KIß║╛N Kß║╛T QUß║ó ─Éß║áT ─É╞»ß╗óC
[62] 1.3.1. Sß║ún phß║⌐m phß║ºn mß╗üm
[63] Sau khi ho├án th├ánh ─æß╗ü t├ái, c├íc sß║ún phß║⌐m dß╗▒ kiß║┐n bao gß╗ôm:
[64] Bß║úng 4: Danh s├ích sß║ún phß║⌐m dß╗▒ kiß║┐n
[66] 1.3.2. Ph╞░╞íng ph├íp v├á quy tr├¼nh
[67] Ph╞░╞íng ph├íp thu thß║¡p dß╗» liß╗çu: Sß╗¡ dß╗Ñng dataset c├┤ng khai FER2013, c├│ thß╗â bß╗ò sung bß║▒ng data augmentation (rotation, flip, zoom, brightness adjustment).
[68] Ph╞░╞íng ph├íp tiß╗ün xß╗¡ l├╜: Pipeline chuß║⌐n h├│a: Face detection ΓåÆ Crop ΓåÆ Resize 48├ù48 ΓåÆ Grayscale ΓåÆ Normalize [0,1].
[69] Ph╞░╞íng ph├íp huß║Ñn luyß╗çn: Transfer Learning tß╗½ pretrained models, fine-tune tr├¬n FER2013, sß╗¡ dß╗Ñng class weights ─æß╗â xß╗¡ l├╜ imbalanced data.
[70] Ph╞░╞íng ph├íp ─æ├ính gi├í: Cross-validation 5-fold, ─æ├ính gi├í tr├¬n test set vß╗¢i c├íc metrics: Accuracy, Precision, Recall, F1-Score, Confusion Matrix.
[71] Quy tr├¼nh triß╗ân khai: Containerization vß╗¢i Docker, deployment tr├¬n local hoß║╖c cloud server.
[72] 1.3.3. Dß╗▒ kiß║┐n c├┤ng bß╗æ khoa hß╗ìc (nß║┐u c├│)
[73] B├ío c├ío ─æß╗ô ├ín tß╗æt nghiß╗çp ─æß║ºy ─æß╗º (50-80 trang)
[74] Poster tr├¼nh b├áy tß║íi hß╗Öi nghß╗ï sinh vi├¬n nghi├¬n cß╗⌐u khoa hß╗ìc (nß║┐u c├│)
[75] B├ái b├ío khoa hß╗ìc gß╗¡i tß║íp ch├¡/hß╗Öi thß║úo trong n╞░ß╗¢c (optional): "X├óy dß╗▒ng hß╗ç thß╗æng nhß║¡n diß╗çn cß║úm x├║c khu├┤n mß║╖t real-time ß╗⌐ng dß╗Ñng trong gi├ío dß╗Ñc trß╗▒c tuyß║┐n"
[76] M├ú nguß╗ôn mß╗ƒ tr├¬n GitHub vß╗¢i giß║Ñy ph├⌐p MIT
[77] 1.4. PH╞»╞áNG PH├üP ─É├üNH GI├ü V├Ç TI├èU CH├ì KIß╗éM THß╗¼
[78] 1.4.1. Ti├¬u ch├¡ ─æ├ính gi├í sß║ún phß║⌐m
[79] Bß║úng 5: Ti├¬u ch├¡ ─æ├ính gi├í chi tiß║┐t
[81] 1.4.2. Ph╞░╞íng ph├íp kiß╗âm thß╗¡
[82] Unit Testing: Kiß╗âm thß╗¡ tß╗½ng module ri├¬ng lß║╗ (face detection, preprocessing, model inference). Tool: pytest, unittest.
[83] Integration Testing: Kiß╗âm thß╗¡ luß╗ông hoß║ít ─æß╗Öng end-to-end tß╗½ input ─æß║┐n output. ─Éß║úm bß║úo c├íc module kß║┐t nß╗æi ─æ├║ng.
[84] Performance Testing: ─Éo FPS, latency, memory usage trong c├íc ─æiß╗üu kiß╗çn kh├íc nhau (1 face, 4 faces, low light, v.v.).
[85] Usability Testing: Cho 5-10 ng╞░ß╗¥i d├╣ng thß╗¡ nghiß╗çm, thu thß║¡p feedback bß║▒ng phiß║┐u khß║úo s├ít SUS (System Usability Scale).
[86] A/B Testing: So s├ính c├íc phi├¬n bß║ún model kh├íc nhau ─æß╗â chß╗ìn model tß╗æt nhß║Ñt.
[87] Cross-browser Testing: Kiß╗âm thß╗¡ extension tr├¬n Chrome, Edge, Firefox.
[88] 1.4.3. Bß╗Ö dß╗» liß╗çu kiß╗âm thß╗¡
[89] FER2013 Test Set: 3,589 ß║únh (ch╞░a tß╗½ng d├╣ng trong training)
[90] RAF-DB Test Set: 3,068 ß║únh (real-world faces)
[91] Self-collected data: Thu thß║¡p tß╗½ webcam vß╗¢i c├íc ─æiß╗üu kiß╗çn ├ính s├íng, g├│c mß║╖t kh├íc nhau (100-200 ß║únh)
[92] Video test cases: 10 video clip ngß║»n (5-10 gi├óy) vß╗¢i c├íc cß║úm x├║c kh├íc nhau
[93] 1.5. Kß║╛ HOß║áCH THß╗░C HIß╗åN V├Ç PH├éN C├öNG C├öNG VIß╗åC
[94] 1.5.1. Kß║┐ hoß║ích thß╗▒c hiß╗çn chi tiß║┐t (16 tuß║ºn)
[95] Bß║úng 6: Kß║┐ hoß║ích thß╗▒c hiß╗çn theo tuß║ºn
[97] 1.5.2. Ph├ón c├┤ng c├┤ng viß╗çc (Dß╗▒ kiß║┐n cho nh├│m 1 ng╞░ß╗¥i)
[98] Bß║úng 7: Ph├ón c├┤ng c├┤ng viß╗çc theo th├ánh vi├¬n
[100] L╞░u ├╜: Nß║┐u thß╗▒c hiß╗çn c├í nh├ón (1 ng╞░ß╗¥i), tß║Ñt cß║ú c├┤ng viß╗çc sß║╜ do sinh vi├¬n ─æß║úm nhß║¡n. Kß║┐ hoß║ích c├│ thß╗â ─æiß╗üu chß╗ënh t├╣y theo tiß║┐n ─æß╗Ö thß╗▒c tß║┐.
[101] Kß║╛T LUß║¼N
[102] ─Éß╗ü t├ái "X├óy dß╗▒ng hß╗ç thß╗æng nhß║¡n diß╗çn cß║úm x├║c khu├┤n mß║╖t theo thß╗¥i gian thß╗▒c trong cuß╗Öc gß╗ìi video" l├á mß╗Öt ─æß╗ü t├ái c├│ t├¡nh cß║Ñp thiß║┐t cao, ß╗⌐ng dß╗Ñng thß╗▒c tiß╗àn lß╗¢n trong bß╗æi cß║únh l├ám viß╗çc v├á hß╗ìc tß║¡p trß╗▒c tuyß║┐n ng├áy c├áng phß╗ò biß║┐n.

Vß╗¢i viß╗çc kß║┐t hß╗úp c├íc c├┤ng nghß╗ç Deep Learning hiß╗çn ─æß║íi (CNN, Transfer Learning) v├á c├íc c├┤ng cß╗Ñ m├ú nguß╗ôn mß╗ƒ, ─æß╗ü t├ái ho├án to├án khß║ú thi trong thß╗¥i gian 16 tuß║ºn vß╗¢i nguß╗ôn lß╗▒c sinh vi├¬n.

Sß║ún phß║⌐m dß╗▒ kiß║┐n sß║╜ ─æß║ít ─æ╞░ß╗úc c├íc ti├¬u ch├¡ kß╗╣ thuß║¡t (accuracy ΓëÑ70%, FPS ΓëÑ15, latency <200ms) v├á c├│ thß╗â ß╗⌐ng dß╗Ñng thß╗▒c tß║┐ trong c├íc l─⌐nh vß╗▒c gi├ío dß╗Ñc trß╗▒c tuyß║┐n, hß╗ìp doanh nghiß╗çp, v├á ch─âm s├│c kh├ích h├áng.
[105] Ng├áy lß║¡p b├ío c├ío: ......./......./.......
