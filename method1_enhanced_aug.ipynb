{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Enhanced Augmentation - FER2013 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPUs: {gpus}\")\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"‚úÖ GPU ENABLED!\")\n",
    "else:\n",
    "    print(\"‚ùå NO GPU! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Drive mounted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASET_PATH = '/content/drive/MyDrive/CaptoneProject/camera'\n",
    "ZIP_PATH = '/content/drive/MyDrive/CaptoneProject/camera.zip'\n",
    "\n",
    "if os.path.exists(ZIP_PATH):\n",
    "    print(f\"‚úÖ ZIP found at {ZIP_PATH}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ZIP not found! Please run the specific zip creation cell if needed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "ZIP_PATH = '/content/drive/MyDrive/CaptoneProject/camera.zip'\n",
    "LOCAL_PATH = '/content/dataset'\n",
    "\n",
    "if not os.path.exists(LOCAL_PATH):\n",
    "    if os.path.exists(ZIP_PATH):\n",
    "        print(\"üì¶ Unzipping... (this might take a moment)\")\n",
    "        !unzip -q -o \"{ZIP_PATH}\" -d /content/\n",
    "        \n",
    "        # Handle directory structure\n",
    "        if os.path.exists('/content/camera'):\n",
    "            !mv /content/camera \"{LOCAL_PATH}\"\n",
    "        elif os.path.exists('/content/train') and os.path.exists('/content/test'):\n",
    "            os.makedirs(LOCAL_PATH, exist_ok=True)\n",
    "            !mv /content/train \"{LOCAL_PATH}/train\"\n",
    "            !mv /content/test \"{LOCAL_PATH}/test\"\n",
    "        print(\"‚úÖ Dataset ready at /content/dataset\")\n",
    "    else:\n",
    "        print(\"‚ùå ZIP file not found in Drive!\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset already exists locally!\")\n",
    "\n",
    "TRAIN_DIR = os.path.join(LOCAL_PATH, 'train')\n",
    "TEST_DIR = os.path.join(LOCAL_PATH, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONFIG: METHOD 1 - ENHANCED AUGMENTATION\n",
    "# ========================================\n",
    "IMG_SIZE = 48\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0005\n",
    "NUM_CLASSES = 7\n",
    "EMOTIONS = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "SEED = 42\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_CHECKPOINT_PATH = f'{CHECKPOINT_DIR}/model_checkpoint.keras'\n",
    "BEST_MODEL_PATH = f'{CHECKPOINT_DIR}/best_model.keras'\n",
    "HISTORY_PATH = f'{CHECKPOINT_DIR}/training_history.pkl'\n",
    "print(f\"üìÅ Checkpoints Saving to: {CHECKPOINT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(IMG_SIZE, IMG_SIZE), color_mode='grayscale', batch_size=BATCH_SIZE, class_mode='categorical', subset='training', shuffle=True, seed=SEED)\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(IMG_SIZE, IMG_SIZE), color_mode='grayscale', batch_size=BATCH_SIZE, class_mode='categorical', subset='validation', shuffle=False, seed=SEED)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR, target_size=(IMG_SIZE, IMG_SIZE), color_mode='grayscale', batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_generator.classes\n",
    "class_weights_array = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(\"üìä Class Weights calculated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Custom CNN (Same as original)\n",
    "def build_cnn(input_shape=(48, 48, 1), num_classes=7):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (3, 3), padding='same', input_shape=input_shape), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.Conv2D(64, (3, 3), padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)), layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.Conv2D(128, (3, 3), padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)), layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(256, (3, 3), padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.Conv2D(256, (3, 3), padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)), layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Conv2D(512, (3, 3), padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.Conv2D(512, (3, 3), padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)), layers.Dropout(0.25),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, kernel_regularizer=regularizers.l2(0.001)), layers.BatchNormalization(), layers.Activation('relu'), layers.Dropout(0.4),\n",
    "        layers.Dense(256, kernel_regularizer=regularizers.l2(0.001)), layers.BatchNormalization(), layers.Activation('relu'), layers.Dropout(0.4),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_cnn()\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1), metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveHistoryCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, history_path, checkpoint_path):\n",
    "        super().__init__()\n",
    "        self.history_path = history_path\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.history_data = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': [], 'lr': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.history_data['accuracy'].append(logs.get('accuracy'))\n",
    "        self.history_data['val_accuracy'].append(logs.get('val_accuracy'))\n",
    "        self.history_data['loss'].append(logs.get('loss'))\n",
    "        self.history_data['val_loss'].append(logs.get('val_loss'))\n",
    "        self.history_data['lr'].append(float(self.model.optimizer.learning_rate.numpy()))\n",
    "\n",
    "        with open(self.history_path, 'wb') as f:\n",
    "            pickle.dump(self.history_data, f)\n",
    "        # Save checkpoint periodically or on best is handled by ModelCheckpoint, \n",
    "        # but we can save here too if needed. \n",
    "        # self.model.save(self.checkpoint_path)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=BEST_MODEL_PATH, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
    "    SaveHistoryCallback(HISTORY_PATH, MODEL_CHECKPOINT_PATH)\n",
    "]\n",
    "print(\"‚úÖ Callbacks configured!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"‚úÖ Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = keras.models.load_model(BEST_MODEL_PATH)\n",
    "\n",
    "test_generator.reset()\n",
    "test_loss, test_acc = best_model.evaluate(test_generator)\n",
    "print(f\"\\nüéØ TEST ACCURACY: {test_acc*100:.2f}%\")\n",
    "print(f\"   TEST LOSS: {test_loss:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "predictions = best_model.predict(test_generator, verbose=1)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=EMOTIONS, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=EMOTIONS, yticklabels=EMOTIONS)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
