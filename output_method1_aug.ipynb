{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PH∆Ø∆†NG PH√ÅP 1: ENHANCED DATA AUGMENTATION\n",
        "# ==========================================\n",
        "\n",
        "# CELL 1: SETUP & GPU CHECK\n",
        "!nvidia-smi\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(\"‚úÖ GPU ENABLED!\")\n",
        "else:\n",
        "    print(\"‚ùå NO GPU! Please enable GPU in Runtime settings.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWVN1y7W47Zc",
        "outputId": "bd01383a-86ea-4a5b-908e-93067df9edcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  5 13:03:00 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "TensorFlow: 2.19.0\n",
            "‚úÖ GPU ENABLED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: IMPORT LIBRARIES\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "metadata": {
        "id": "TICiH2tx5QHv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: MOUNT DRIVE & CONFIG PATHS\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n\n",
        "BASE_DIR = '/content/drive/MyDrive/CaptoneProject'\n",
        "ZIP_PATH = f'{BASE_DIR}/camera.zip'\n",
        "LOCAL_PATH = '/content/dataset'\n",
        "CHECKPOINT_DIR = f'{BASE_DIR}/checkpoints/method1_aug'\n",
        "\n",
        "# T·∫°o th∆∞ m·ª•c l∆∞u checkpoint\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "MODEL_CHECKPOINT_PATH = f'{CHECKPOINT_DIR}/model_checkpoint.keras'\n",
        "BEST_MODEL_PATH = f'{CHECKPOINT_DIR}/best_model.keras'\n",
        "HISTORY_PATH = f'{CHECKPOINT_DIR}/training_history.pkl'\n",
        "\n",
        "print(f\"üìÇ Dataset ZIP: {ZIP_PATH}\")\n",
        "print(f\"üíæ Checkpoints will be saved to: {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubv80ikC5QR_",
        "outputId": "b4ec8c04-350d-4253-9486-bd9fdc932a7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "üìÇ Dataset ZIP: /content/drive/MyDrive/CaptoneProject/camera.zip\n",
            "üíæ Checkpoints will be saved to: /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: EXTRACT DATASET\n",
        "if not os.path.exists(LOCAL_PATH):\n",
        "    if os.path.exists(ZIP_PATH):\n",
        "        print(\"üì¶ Unzipping dataset... (please wait)\")\n",
        "        !unzip -q -o \"{ZIP_PATH}\" -d /content/\n",
        "\n",
        "        # X·ª≠ l√Ω c·∫•u tr√∫c th∆∞ m·ª•c sau khi unzip\n",
        "        if os.path.exists('/content/camera'):\n",
        "            !mv /content/camera \"{LOCAL_PATH}\"\n",
        "        elif os.path.exists('/content/train') and os.path.exists('/content/test'):\n",
        "            os.makedirs(LOCAL_PATH, exist_ok=True)\n",
        "            !mv /content/train \"{LOCAL_PATH}/train\"\n",
        "            !mv /content/test \"{LOCAL_PATH}/test\"\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Check ZIP structure!\")\n",
        "\n",
        "        print(\"‚úÖ Dataset ready at /content/dataset\")\n",
        "    else:\n",
        "        print(\"‚ùå ZIP file not found!\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already exists locally.\")\n",
        "\n",
        "TRAIN_DIR = os.path.join(LOCAL_PATH, 'train')\n",
        "TEST_DIR = os.path.join(LOCAL_PATH, 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OMPMU5W4_mk",
        "outputId": "e3562012-66cc-4a75-badc-2d29746b2527"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Unzipping dataset... (please wait)\n",
            "‚úÖ Dataset ready at /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: HYPERPARAMETERS & DATA GENERATORS (ENHANCED)\n",
        "IMG_SIZE = 48\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.0005\n",
        "NUM_CLASSES = 7\n",
        "SEED = 42\n",
        "EMOTIONS = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# --- KEY CHANGE: Enhanced Augmentation ---\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,           # TƒÉng g√≥c xoay\n",
        "    width_shift_range=0.2,       # TƒÉng d·ªãch chuy·ªÉn\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.7, 1.3], # Th√™m ƒë·ªô s√°ng\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "print(\"üîÑ Loading Data Generators...\")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Class Weights\n",
        "train_labels = train_generator.classes\n",
        "class_weights_array = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = dict(enumerate(class_weights_array))\n",
        "print(\"‚öñÔ∏è Class Weights Calculated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzqEPNto4_tU",
        "outputId": "76e04296-51d2-42af-8594-843184a84229"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading Data Generators...\n",
            "Found 22968 images belonging to 7 classes.\n",
            "Found 5741 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n",
            "‚öñÔ∏è Class Weights Calculated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: BUILD MODEL (Standard CNN)\n",
        "def build_cnn(input_shape=(48, 48, 1), num_classes=7):\n",
        "    model = models.Sequential([\n",
        "        # Block 1\n",
        "        layers.Conv2D(64, (3, 3), padding='same', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Block 2\n",
        "        layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Block 3\n",
        "        layers.Conv2D(256, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(256, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Block 4\n",
        "        layers.Conv2D(512, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Conv2D(512, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Classification Head\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Dense(256, kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_cnn()\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(\"üèóÔ∏è Model Built (Standard CNN)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEnO-1654_v0",
        "outputId": "b3a61e93-5368-4513-ad17-92a1cf3c04aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèóÔ∏è Model Built (Standard CNN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: TRAINING CALLBACKS\n",
        "class SaveHistoryCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, history_path):\n",
        "        super().__init__()\n",
        "        self.history_path = history_path\n",
        "        self.history_data = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': [], 'lr': []}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for k, v in logs.items():\n",
        "            if k in self.history_data:\n",
        "                self.history_data[k].append(v)\n",
        "        # Add LR manually if not in logs\n",
        "        lr = float(self.model.optimizer.learning_rate.numpy())\n",
        "        if len(self.history_data['lr']) < len(self.history_data['loss']):\n",
        "             self.history_data['lr'].append(lr)\n",
        "\n",
        "        with open(self.history_path, 'wb') as f:\n",
        "            pickle.dump(self.history_data, f)\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath=BEST_MODEL_PATH, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=12, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
        "    SaveHistoryCallback(HISTORY_PATH)\n",
        "]"
      ],
      "metadata": {
        "id": "apbZb3gN4_yN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: START TRAINING\n",
        "print(\"üöÄ Starting Training (Method 1)...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBMjRu_h4_0l",
        "outputId": "a0349563-28bc-4ae4-c95d-519cc876cf96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Training (Method 1)...\n",
            "Epoch 1/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.1500 - loss: 3.5056\n",
            "Epoch 1: val_accuracy improved from -inf to 0.01881, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 145ms/step - accuracy: 0.1500 - loss: 3.5052 - val_accuracy: 0.0188 - val_loss: 3.0580 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1523 - loss: 3.0584\n",
            "Epoch 2: val_accuracy improved from 0.01881 to 0.15346, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.1523 - loss: 3.0581 - val_accuracy: 0.1535 - val_loss: 2.6934 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.1460 - loss: 2.7528\n",
            "Epoch 3: val_accuracy did not improve from 0.15346\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - accuracy: 0.1460 - loss: 2.7525 - val_accuracy: 0.0765 - val_loss: 2.4995 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1569 - loss: 2.4804\n",
            "Epoch 4: val_accuracy did not improve from 0.15346\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.1569 - loss: 2.4802 - val_accuracy: 0.1404 - val_loss: 2.2976 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1654 - loss: 2.2971\n",
            "Epoch 5: val_accuracy improved from 0.15346 to 0.21442, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.1655 - loss: 2.2970 - val_accuracy: 0.2144 - val_loss: 2.1527 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.1855 - loss: 2.1835\n",
            "Epoch 6: val_accuracy did not improve from 0.21442\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 94ms/step - accuracy: 0.1855 - loss: 2.1834 - val_accuracy: 0.1707 - val_loss: 3.9056 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1931 - loss: 2.1325\n",
            "Epoch 7: val_accuracy improved from 0.21442 to 0.22801, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.1931 - loss: 2.1324 - val_accuracy: 0.2280 - val_loss: 2.0731 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2161 - loss: 2.0589\n",
            "Epoch 8: val_accuracy did not improve from 0.22801\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.2161 - loss: 2.0588 - val_accuracy: 0.1648 - val_loss: 2.1396 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2250 - loss: 2.0293\n",
            "Epoch 9: val_accuracy improved from 0.22801 to 0.22888, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 90ms/step - accuracy: 0.2250 - loss: 2.0292 - val_accuracy: 0.2289 - val_loss: 1.9938 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2486 - loss: 1.9861\n",
            "Epoch 10: val_accuracy improved from 0.22888 to 0.27417, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 90ms/step - accuracy: 0.2487 - loss: 1.9860 - val_accuracy: 0.2742 - val_loss: 1.9740 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3007 - loss: 1.8939\n",
            "Epoch 11: val_accuracy improved from 0.27417 to 0.34036, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 93ms/step - accuracy: 0.3007 - loss: 1.8940 - val_accuracy: 0.3404 - val_loss: 1.8860 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3271 - loss: 1.8692\n",
            "Epoch 12: val_accuracy did not improve from 0.34036\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.3272 - loss: 1.8692 - val_accuracy: 0.3236 - val_loss: 1.9159 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3539 - loss: 1.8330\n",
            "Epoch 13: val_accuracy did not improve from 0.34036\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 90ms/step - accuracy: 0.3539 - loss: 1.8329 - val_accuracy: 0.1761 - val_loss: 2.3237 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3910 - loss: 1.7744\n",
            "Epoch 14: val_accuracy improved from 0.34036 to 0.36474, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.3910 - loss: 1.7744 - val_accuracy: 0.3647 - val_loss: 1.8252 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4017 - loss: 1.7688\n",
            "Epoch 15: val_accuracy did not improve from 0.36474\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.4017 - loss: 1.7688 - val_accuracy: 0.3499 - val_loss: 1.8415 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4229 - loss: 1.7204\n",
            "Epoch 16: val_accuracy improved from 0.36474 to 0.42048, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 101ms/step - accuracy: 0.4229 - loss: 1.7204 - val_accuracy: 0.4205 - val_loss: 1.7190 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4380 - loss: 1.6846\n",
            "Epoch 17: val_accuracy did not improve from 0.42048\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 92ms/step - accuracy: 0.4381 - loss: 1.6845 - val_accuracy: 0.4088 - val_loss: 1.7612 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4435 - loss: 1.6718\n",
            "Epoch 18: val_accuracy did not improve from 0.42048\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 84ms/step - accuracy: 0.4436 - loss: 1.6718 - val_accuracy: 0.3132 - val_loss: 1.9888 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4601 - loss: 1.6528\n",
            "Epoch 19: val_accuracy improved from 0.42048 to 0.46142, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 93ms/step - accuracy: 0.4601 - loss: 1.6528 - val_accuracy: 0.4614 - val_loss: 1.6465 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4672 - loss: 1.6555\n",
            "Epoch 20: val_accuracy did not improve from 0.46142\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.4672 - loss: 1.6555 - val_accuracy: 0.4227 - val_loss: 1.7207 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4716 - loss: 1.6316\n",
            "Epoch 21: val_accuracy improved from 0.46142 to 0.47309, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 92ms/step - accuracy: 0.4716 - loss: 1.6316 - val_accuracy: 0.4731 - val_loss: 1.5953 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4745 - loss: 1.6052\n",
            "Epoch 22: val_accuracy did not improve from 0.47309\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 92ms/step - accuracy: 0.4745 - loss: 1.6052 - val_accuracy: 0.4656 - val_loss: 1.6698 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4883 - loss: 1.5862\n",
            "Epoch 23: val_accuracy did not improve from 0.47309\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 85ms/step - accuracy: 0.4883 - loss: 1.5862 - val_accuracy: 0.4626 - val_loss: 1.6559 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4875 - loss: 1.5850\n",
            "Epoch 24: val_accuracy did not improve from 0.47309\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 90ms/step - accuracy: 0.4876 - loss: 1.5850 - val_accuracy: 0.4543 - val_loss: 1.7341 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5018 - loss: 1.5581\n",
            "Epoch 25: val_accuracy improved from 0.47309 to 0.48058, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.5018 - loss: 1.5581 - val_accuracy: 0.4806 - val_loss: 1.5956 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5052 - loss: 1.5534\n",
            "Epoch 26: val_accuracy improved from 0.48058 to 0.51803, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.5052 - loss: 1.5534 - val_accuracy: 0.5180 - val_loss: 1.5383 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5120 - loss: 1.5588\n",
            "Epoch 27: val_accuracy did not improve from 0.51803\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 94ms/step - accuracy: 0.5120 - loss: 1.5588 - val_accuracy: 0.4886 - val_loss: 1.5950 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5185 - loss: 1.5230\n",
            "Epoch 28: val_accuracy did not improve from 0.51803\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.5185 - loss: 1.5231 - val_accuracy: 0.5064 - val_loss: 1.5783 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5176 - loss: 1.5333\n",
            "Epoch 29: val_accuracy did not improve from 0.51803\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.5176 - loss: 1.5333 - val_accuracy: 0.5044 - val_loss: 1.5553 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5243 - loss: 1.5225\n",
            "Epoch 30: val_accuracy did not improve from 0.51803\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.5243 - loss: 1.5225 - val_accuracy: 0.4330 - val_loss: 1.7569 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5234 - loss: 1.5121\n",
            "Epoch 31: val_accuracy improved from 0.51803 to 0.52047, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5234 - loss: 1.5121 - val_accuracy: 0.5205 - val_loss: 1.5550 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5429 - loss: 1.4726\n",
            "Epoch 32: val_accuracy improved from 0.52047 to 0.55304, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 97ms/step - accuracy: 0.5429 - loss: 1.4726 - val_accuracy: 0.5530 - val_loss: 1.4341 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5578 - loss: 1.4183\n",
            "Epoch 33: val_accuracy improved from 0.55304 to 0.56523, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 93ms/step - accuracy: 0.5578 - loss: 1.4184 - val_accuracy: 0.5652 - val_loss: 1.4155 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5509 - loss: 1.4065\n",
            "Epoch 34: val_accuracy did not improve from 0.56523\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 90ms/step - accuracy: 0.5509 - loss: 1.4065 - val_accuracy: 0.5647 - val_loss: 1.4126 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5543 - loss: 1.4030\n",
            "Epoch 35: val_accuracy did not improve from 0.56523\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.5543 - loss: 1.4030 - val_accuracy: 0.5543 - val_loss: 1.4283 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5666 - loss: 1.4011\n",
            "Epoch 36: val_accuracy did not improve from 0.56523\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.5666 - loss: 1.4011 - val_accuracy: 0.5422 - val_loss: 1.4352 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5544 - loss: 1.3995\n",
            "Epoch 37: val_accuracy improved from 0.56523 to 0.57934, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 102ms/step - accuracy: 0.5544 - loss: 1.3995 - val_accuracy: 0.5793 - val_loss: 1.3663 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5685 - loss: 1.3648\n",
            "Epoch 38: val_accuracy did not improve from 0.57934\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.5685 - loss: 1.3648 - val_accuracy: 0.5748 - val_loss: 1.3767 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5624 - loss: 1.3845\n",
            "Epoch 39: val_accuracy did not improve from 0.57934\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.5625 - loss: 1.3845 - val_accuracy: 0.5604 - val_loss: 1.4171 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5773 - loss: 1.3588\n",
            "Epoch 40: val_accuracy improved from 0.57934 to 0.58544, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5772 - loss: 1.3589 - val_accuracy: 0.5854 - val_loss: 1.3709 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5784 - loss: 1.3675\n",
            "Epoch 41: val_accuracy did not improve from 0.58544\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5784 - loss: 1.3675 - val_accuracy: 0.5663 - val_loss: 1.3953 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5750 - loss: 1.3431\n",
            "Epoch 42: val_accuracy did not improve from 0.58544\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 100ms/step - accuracy: 0.5750 - loss: 1.3431 - val_accuracy: 0.5426 - val_loss: 1.4474 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5816 - loss: 1.3347\n",
            "Epoch 43: val_accuracy did not improve from 0.58544\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 85ms/step - accuracy: 0.5816 - loss: 1.3346 - val_accuracy: 0.5839 - val_loss: 1.3558 - learning_rate: 1.2500e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5890 - loss: 1.3252\n",
            "Epoch 44: val_accuracy improved from 0.58544 to 0.58875, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5890 - loss: 1.3252 - val_accuracy: 0.5887 - val_loss: 1.3520 - learning_rate: 1.2500e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5910 - loss: 1.3125\n",
            "Epoch 45: val_accuracy did not improve from 0.58875\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 90ms/step - accuracy: 0.5910 - loss: 1.3125 - val_accuracy: 0.5837 - val_loss: 1.3447 - learning_rate: 1.2500e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5997 - loss: 1.2985\n",
            "Epoch 46: val_accuracy improved from 0.58875 to 0.58944, saving model to /content/drive/MyDrive/CaptoneProject/checkpoints/method1_aug/best_model.keras\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 86ms/step - accuracy: 0.5997 - loss: 1.2985 - val_accuracy: 0.5894 - val_loss: 1.3274 - learning_rate: 1.2500e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5952 - loss: 1.2850\n",
            "Epoch 47: val_accuracy did not improve from 0.58944\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 103ms/step - accuracy: 0.5952 - loss: 1.2850 - val_accuracy: 0.5774 - val_loss: 1.3502 - learning_rate: 1.2500e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5957 - loss: 1.2977\n",
            "Epoch 48: val_accuracy did not improve from 0.58944\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 87ms/step - accuracy: 0.5957 - loss: 1.2977 - val_accuracy: 0.5839 - val_loss: 1.3434 - learning_rate: 1.2500e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6107 - loss: 1.2779\n",
            "Epoch 49: val_accuracy did not improve from 0.58944\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - accuracy: 0.6107 - loss: 1.2779 - val_accuracy: 0.5842 - val_loss: 1.3555 - learning_rate: 1.2500e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6027 - loss: 1.2772\n",
            "Epoch 50: val_accuracy did not improve from 0.58944\n",
            "\u001b[1m359/359\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - accuracy: 0.6027 - loss: 1.2772 - val_accuracy: 0.5877 - val_loss: 1.3342 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 46.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: EVALUATION\n",
        "print(\"\\nüìä Evaluating Best Model...\")\n",
        "best_model = keras.models.load_model(BEST_MODEL_PATH)\n",
        "test_loss, test_acc = best_model.evaluate(test_generator)\n",
        "print(f\"üèÜ Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "predictions = best_model.predict(test_generator)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = test_generator.classes\n",
        "print(classification_report(y_true, y_pred, target_names=EMOTIONS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcWlmJFQ4_3V",
        "outputId": "a962193e-39c3-492d-e5a6-38a068a497e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Evaluating Best Model...\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.5731 - loss: 1.3405\n",
            "üèÜ Test Accuracy: 0.6293\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.60      0.50      0.55       958\n",
            "     disgust       0.40      0.72      0.52       111\n",
            "        fear       0.49      0.35      0.41      1024\n",
            "       happy       0.85      0.85      0.85      1774\n",
            "     neutral       0.54      0.68      0.60      1233\n",
            "         sad       0.49      0.51      0.50      1247\n",
            "    surprise       0.75      0.74      0.75       831\n",
            "\n",
            "    accuracy                           0.63      7178\n",
            "   macro avg       0.59      0.62      0.60      7178\n",
            "weighted avg       0.63      0.63      0.63      7178\n",
            "\n"
          ]
        }
      ]
    }
  ]
}